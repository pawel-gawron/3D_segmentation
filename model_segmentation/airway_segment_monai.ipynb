{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.3.0\n",
      "Numpy version: 1.24.4\n",
      "Pytorch version: 2.2.1+cu121\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 865972f7a791bf7b42efbcd87c8402bd865b329e\n",
      "MONAI __file__: /home/<username>/Documents/RISA/3D_segmentation/.venv/lib/python3.10/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 5.2.1\n",
      "scikit-image version: 0.22.0\n",
      "scipy version: 1.12.0\n",
      "Pillow version: 10.2.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.17.1+cu121\n",
      "tqdm version: 4.66.2\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.8\n",
      "pandas version: 2.2.1\n",
      "einops version: 0.7.0\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning\n",
    "from monai.utils import set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, list_data_collate, decollate_batch#, DataLoader\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "/home/pawel/Documents/RISA/3D_segmentation/MONAI_DATA_DIRECTORY\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "print(directory)\n",
    "root_dir = Path(\"/home/pawel/Documents/RISA/3D_segmentation/MONAI_DATA_DIRECTORY\")\n",
    "print(root_dir)\n",
    "data_dir = os.path.join(root_dir, \"Task09_Spleen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task09_Spleen.tar: 0.00B [00:00, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task09_Spleen.tar: 1.50GB [01:41, 15.8MB/s]                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-25 12:35:41,062 - INFO - Downloaded: /home/pawel/Documents/RISA/3D_segmentation/MONAI_DATA_DIRECTORY/Task09_Spleen.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-25 12:35:42,907 - INFO - Verified 'Task09_Spleen.tar', md5: 410d4a301da4e5b2f6f86ec3ddba524e.\n",
      "2024-03-25 12:35:42,908 - INFO - Writing into directory: /home/pawel/Documents/RISA/3D_segmentation/MONAI_DATA_DIRECTORY.\n"
     ]
    }
   ],
   "source": [
    "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task09_Spleen.tar\"\n",
    "md5 = \"410d4a301da4e5b2f6f86ec3ddba524e\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"Task09_Spleen.tar\")\n",
    "data_dir = os.path.join(root_dir, \"Task09_Spleen\")\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTDataset(Dataset):\n",
    "    def __init__(self, images_filepaths, transform=None):\n",
    "        self.images_filepaths = images_filepaths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.images_filepaths[idx]\n",
    "        image_file = np.load(str(image_filepath))\n",
    "\n",
    "        path_elements = list(Path(image_filepath).parts)\n",
    "        index = path_elements.index('scans')\n",
    "        path_elements[index] = 'airways'\n",
    "\n",
    "        mask_filepath = os.path.join(*path_elements)\n",
    "        mask_file = np.load(str(mask_filepath))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            transformed_images = []\n",
    "            transformed_masks = []\n",
    "            for i in range(0, image_file.shape[-1]):\n",
    "                \n",
    "                image_slice = image_file[..., i]\n",
    "                mask_slice = mask_file[..., i]\n",
    "\n",
    "                transformed = self.transform(image=image_slice, mask=mask_slice)\n",
    "\n",
    "                transformed_images.append(transformed[\"image\"])\n",
    "                transformed_masks.append(transformed[\"mask\"])\n",
    "\n",
    "            image_file = torch.stack(transformed_images, dim=0)\n",
    "            mask_file = torch.stack(transformed_masks, dim=0).type(torch.float16)\n",
    "            mask_file = mask_file.unsqueeze(0)\n",
    "\n",
    "            image_file = image_file.permute(1, 0, 2, 3)\n",
    "\n",
    "        return image_file, mask_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.augmentations = A.Compose([\n",
    "        A.ToFloat(max_value=1024+400, always_apply=True),\n",
    "        A.Resize(height=64, width=64),\n",
    "        # A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
    "        # A.RandomBrightnessContrast(p=0.5),\n",
    "        # A.Normalize(mean=[-1024/400], std=[1/400], always_apply=True),\n",
    "        ToTensorV2()\n",
    "        ])\n",
    "        self.transforms = A.Compose([\n",
    "        A.ToFloat(max_value=1024+400, always_apply=True),\n",
    "        A.Resize(height=64, width=64),\n",
    "        # A.Normalize(mean=[-1024/400], std=[1/400], always_apply=True),\n",
    "        ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        self.test_dataset = None\n",
    "\n",
    "        self.path_to_file = '/home/pawel/Documents/RISA/3D_segmentation/dataset'\n",
    "\n",
    "\n",
    "    def prepare_data(self):\n",
    "        if os.path.exists(self.path_to_file):\n",
    "            print(\"Path exists\")\n",
    "            images_paths = sorted(Path(self.path_to_file).rglob('*.npy'))\n",
    "            # print(images_paths)\n",
    "            for image_path in images_paths:\n",
    "                image = np.load(str(image_path))\n",
    "\n",
    "                if image is None:\n",
    "                    print(\"Unlink image: \", image_path)\n",
    "                    image_path.unlink()\n",
    "        else:\n",
    "            print(\"Path does not exist\")\n",
    "\n",
    "\n",
    "    def setup(self, stage):\n",
    "        paths = sorted(Path(os.path.join(self.path_to_file, 'scans')).glob('*.npy'))\n",
    "\n",
    "        train_paths, val_paths = train_test_split(paths, test_size=0.3, random_state=42)\n",
    "        # val_paths, test_paths = train_test_split(val_paths, test_size=0.5, random_state=42)\n",
    "\n",
    "        self.train_dataset = CTDataset(train_paths, transform=self.augmentations)\n",
    "        self.val_dataset = CTDataset(val_paths, transform=self.transforms) \n",
    "        # self.test_dataset = CTDataset(test_paths, transform=self.transforms)\n",
    "\n",
    "        # return self.train_dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # print(DataLoader(self.train_dataset, batch_size=1).shape)\n",
    "        return DataLoader(self.train_dataset, batch_size=1, num_workers=1)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=1, num_workers=1)\n",
    "\n",
    "    # def test_dataloader(self):\n",
    "    #     return DataLoader(self.test_dataset, batch_size=5, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from x_unet import XUnet\n",
    "\n",
    "class Net(pytorch_lightning.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._model = UNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=2,\n",
    "            channels=(16, 32, 64, 128, 256),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,\n",
    "            norm=Norm.BATCH,\n",
    "        )\n",
    "\n",
    "        self.loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "        self.post_pred = Compose([EnsureType(\"tensor\", device=\"cpu\"), AsDiscrete(argmax=True, to_onehot=2)])\n",
    "        self.post_label = Compose([EnsureType(\"tensor\", device=\"cpu\"), AsDiscrete(to_onehot=2)])\n",
    "        self.dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "        self.best_val_dice = 0\n",
    "        self.best_val_epoch = 0\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "        self.augmentations = A.Compose([\n",
    "            A.ToFloat(max_value=1024+400, always_apply=True),\n",
    "            A.Resize(height=128, width=128),\n",
    "            # A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
    "            # A.RandomBrightnessContrast(p=0.5),\n",
    "            # A.Normalize(mean=[-1024/400], std=[1/400], always_apply=True),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "        self.transforms = A.Compose([\n",
    "            A.ToFloat(max_value=1024+400, always_apply=True),\n",
    "            A.Resize(height=128, width=128),\n",
    "            # A.Normalize(mean=[-1024/400], std=[1/400], always_apply=True),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        self.path_to_file = '/home/pawel/Documents/RISA/3D_segmentation/dataset'\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._model(x)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        if os.path.exists(self.path_to_file):\n",
    "            print(\"Path exists\")\n",
    "            images_paths = sorted(Path(self.path_to_file).rglob('*.npy'))\n",
    "            # print(images_paths)\n",
    "            for image_path in images_paths:\n",
    "                image = np.load(str(image_path))\n",
    "\n",
    "                if image is None:\n",
    "                    print(\"Unlink image: \", image_path)\n",
    "                    image_path.unlink()\n",
    "        else:\n",
    "            print(\"Path does not exist\")\n",
    "\n",
    "        paths = sorted(Path(os.path.join(self.path_to_file, 'scans')).glob('*.npy'))\n",
    "\n",
    "        train_paths, val_paths = train_test_split(paths, test_size=0.3, random_state=42)\n",
    "\n",
    "        self.train_ds = CTDataset(train_paths, transform=self.augmentations)\n",
    "        self.val_ds = CTDataset(val_paths, transform=self.transforms)\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_loader = DataLoader(\n",
    "            self.train_ds,\n",
    "            batch_size=8,\n",
    "            shuffle=True,\n",
    "            num_workers=6,\n",
    "            collate_fn=list_data_collate,\n",
    "        )\n",
    "        print(\"DataLoader: \", train_loader)\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_loader = DataLoader(self.val_ds, batch_size=4, num_workers=6)\n",
    "        return val_loader\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self._model.parameters(), 1e-4)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        output = self.forward(images)\n",
    "        loss = self.loss_function(output, labels)\n",
    "        tensorboard_logs = {\"train_loss\": loss.item()}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        roi_size = (160, 160, 160)\n",
    "        sw_batch_size = 4\n",
    "        outputs = sliding_window_inference(images, roi_size, sw_batch_size, self.forward)\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        outputs = [self.post_pred(i) for i in decollate_batch(outputs)]\n",
    "        labels = [self.post_label(i) for i in decollate_batch(labels)]\n",
    "        self.dice_metric(y_pred=outputs, y=labels)\n",
    "        d = {\"val_loss\": loss, \"val_number\": len(outputs)}\n",
    "        self.validation_step_outputs.append(d)\n",
    "        return d\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        val_loss, num_items = 0, 0\n",
    "        for output in self.validation_step_outputs:\n",
    "            val_loss += output[\"val_loss\"].sum().item()\n",
    "            num_items += output[\"val_number\"]\n",
    "        mean_val_dice = self.dice_metric.aggregate().item()\n",
    "        self.dice_metric.reset()\n",
    "        mean_val_loss = torch.tensor(val_loss / num_items)\n",
    "        tensorboard_logs = {\n",
    "            \"val_dice\": mean_val_dice,\n",
    "            \"val_loss\": mean_val_loss,\n",
    "        }\n",
    "        if mean_val_dice > self.best_val_dice:\n",
    "            self.best_val_dice = mean_val_dice\n",
    "            self.best_val_epoch = self.current_epoch\n",
    "        print(\n",
    "            f\"current epoch: {self.current_epoch} \"\n",
    "            f\"current mean dice: {mean_val_dice:.4f}\"\n",
    "            f\"\\nbest mean dice: {self.best_val_dice:.4f} \"\n",
    "            f\"at epoch: {self.best_val_epoch}\"\n",
    "        )\n",
    "        self.validation_step_outputs.clear()  # free memory\n",
    "        return {\"log\": tensorboard_logs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type     | Params\n",
      "-------------------------------------------\n",
      "0 | _model        | UNet     | 4.8 M \n",
      "1 | loss_function | DiceLoss | 0     \n",
      "-------------------------------------------\n",
      "4.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.8 M     Total params\n",
      "19.236    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]current epoch: 0 current mean dice: 0.0069\n",
      "best mean dice: 0.0069 at epoch: 0\n",
      "DataLoader:  <torch.utils.data.dataloader.DataLoader object at 0x759a9f4e2530>\n",
      "Epoch 0:  20%|██        | 15/75 [00:04<00:16,  3.70it/s, v_num=272]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawel/Documents/RISA/3D_segmentation/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "# initialise the LightningModule\n",
    "net = Net()\n",
    "\n",
    "# data_module = CTDataModule()\n",
    "\n",
    "# set up loggers and checkpoints\n",
    "log_dir = os.path.join(root_dir, \"logs\")\n",
    "# tb_logger = pytorch_lightning.loggers.TensorBoardLogger(save_dir=log_dir)\n",
    "\n",
    "# initialise Lightning's trainer.\n",
    "trainer = pytorch_lightning.Trainer(\n",
    "    devices=[0],\n",
    "    max_epochs=600,\n",
    "    # logger=tb_logger,\n",
    "    enable_checkpointing=True,\n",
    "    num_sanity_val_steps=1,\n",
    "    log_every_n_steps=16,\n",
    ")\n",
    "\n",
    "# train\n",
    "trainer.fit(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if directory is None:\n",
    "    shutil.rmtree(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of images and labels: <class 'nibabel.nifti1.Nifti1Image'>\n",
      "shapes of images and labels: (512, 512, 90)\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "img = nib.load('/home/pawel/Documents/RISA/3D_segmentation/MONAI_DATA_DIRECTORY/Task09_Spleen/imagesTr/spleen_2.nii.gz')\n",
    "\n",
    "print(\"type of images and labels:\", type(img))\n",
    "print(\"shapes of images and labels:\", img.shape)\n",
    "# print(images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
