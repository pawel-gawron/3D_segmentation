{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.3.0\n",
      "Numpy version: 1.24.4\n",
      "Pytorch version: 2.2.1+cu121\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 865972f7a791bf7b42efbcd87c8402bd865b329e\n",
      "MONAI __file__: /home/<username>/Documents/RISA/3D_segmentation/.venv/lib/python3.10/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 5.2.1\n",
      "scikit-image version: 0.22.0\n",
      "scipy version: 1.12.0\n",
      "Pillow version: 10.2.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.17.1+cu121\n",
      "tqdm version: 4.66.2\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.8\n",
      "pandas version: 2.2.1\n",
      "einops version: 0.7.0\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning\n",
    "from monai.utils import set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, list_data_collate, decollate_batch, DataLoader\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "/tmp/tmpkl7slnr6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "print(directory)\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task09_Spleen.tar: 1.50GB [01:42, 15.7MB/s]                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-23 13:36:42,674 - INFO - Downloaded: /tmp/tmpkl7slnr6/Task09_Spleen.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-23 13:36:44,489 - INFO - Verified 'Task09_Spleen.tar', md5: 410d4a301da4e5b2f6f86ec3ddba524e.\n",
      "2024-03-23 13:36:44,490 - INFO - Writing into directory: /tmp/tmpkl7slnr6.\n"
     ]
    }
   ],
   "source": [
    "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task09_Spleen.tar\"\n",
    "md5 = \"410d4a301da4e5b2f6f86ec3ddba524e\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"Task09_Spleen.tar\")\n",
    "data_dir = os.path.join(root_dir, \"Task09_Spleen\")\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(pytorch_lightning.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._model = UNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=2,\n",
    "            channels=(16, 32, 64, 128, 256),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,\n",
    "            norm=Norm.BATCH,\n",
    "        )\n",
    "        self.loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "        self.post_pred = Compose([EnsureType(\"tensor\", device=\"cpu\"), AsDiscrete(argmax=True, to_onehot=2)])\n",
    "        self.post_label = Compose([EnsureType(\"tensor\", device=\"cpu\"), AsDiscrete(to_onehot=2)])\n",
    "        self.dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "        self.best_val_dice = 0\n",
    "        self.best_val_epoch = 0\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._model(x)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # set up the correct data path\n",
    "        train_images = sorted(glob.glob(os.path.join(data_dir, \"imagesTr\", \"*.nii.gz\")))\n",
    "        train_labels = sorted(glob.glob(os.path.join(data_dir, \"labelsTr\", \"*.nii.gz\")))\n",
    "        data_dicts = [\n",
    "            {\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(train_images, train_labels)\n",
    "        ]\n",
    "        train_files, val_files = data_dicts[:-9], data_dicts[-9:]\n",
    "\n",
    "        # set deterministic training for reproducibility\n",
    "        set_determinism(seed=0)\n",
    "\n",
    "        # define the data transforms\n",
    "        train_transforms = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "                Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                Spacingd(\n",
    "                    keys=[\"image\", \"label\"],\n",
    "                    pixdim=(1.5, 1.5, 2.0),\n",
    "                    mode=(\"bilinear\", \"nearest\"),\n",
    "                ),\n",
    "                ScaleIntensityRanged(\n",
    "                    keys=[\"image\"],\n",
    "                    a_min=-57,\n",
    "                    a_max=164,\n",
    "                    b_min=0.0,\n",
    "                    b_max=1.0,\n",
    "                    clip=True,\n",
    "                ),\n",
    "                CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "                # randomly crop out patch samples from\n",
    "                # big image based on pos / neg ratio\n",
    "                # the image centers of negative samples\n",
    "                # must be in valid image area\n",
    "                RandCropByPosNegLabeld(\n",
    "                    keys=[\"image\", \"label\"],\n",
    "                    label_key=\"label\",\n",
    "                    spatial_size=(96, 96, 96),\n",
    "                    pos=1,\n",
    "                    neg=1,\n",
    "                    num_samples=4,\n",
    "                    image_key=\"image\",\n",
    "                    image_threshold=0,\n",
    "                ),\n",
    "                # user can also add other random transforms\n",
    "                #                 RandAffined(\n",
    "                #                     keys=['image', 'label'],\n",
    "                #                     mode=('bilinear', 'nearest'),\n",
    "                #                     prob=1.0,\n",
    "                #                     spatial_size=(96, 96, 96),\n",
    "                #                     rotate_range=(0, 0, np.pi/15),\n",
    "                #                     scale_range=(0.1, 0.1, 0.1)),\n",
    "            ]\n",
    "        )\n",
    "        val_transforms = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "                Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                Spacingd(\n",
    "                    keys=[\"image\", \"label\"],\n",
    "                    pixdim=(1.5, 1.5, 2.0),\n",
    "                    mode=(\"bilinear\", \"nearest\"),\n",
    "                ),\n",
    "                ScaleIntensityRanged(\n",
    "                    keys=[\"image\"],\n",
    "                    a_min=-57,\n",
    "                    a_max=164,\n",
    "                    b_min=0.0,\n",
    "                    b_max=1.0,\n",
    "                    clip=True,\n",
    "                ),\n",
    "                CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # we use cached datasets - these are 10x faster than regular datasets\n",
    "        self.train_ds = CacheDataset(\n",
    "            data=train_files,\n",
    "            transform=train_transforms,\n",
    "            cache_rate=1.0,\n",
    "            num_workers=4,\n",
    "        )\n",
    "        self.val_ds = CacheDataset(\n",
    "            data=val_files,\n",
    "            transform=val_transforms,\n",
    "            cache_rate=1.0,\n",
    "            num_workers=4,\n",
    "        )\n",
    "\n",
    "    #         self.train_ds = monai.data.Dataset(\n",
    "    #             data=train_files, transform=train_transforms)\n",
    "    #         self.val_ds = monai.data.Dataset(\n",
    "    #             data=val_files, transform=val_transforms)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_loader = DataLoader(\n",
    "            self.train_ds,\n",
    "            batch_size=2,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            collate_fn=list_data_collate,\n",
    "        )\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_loader = DataLoader(self.val_ds, batch_size=1, num_workers=4)\n",
    "        return val_loader\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self._model.parameters(), 1e-4)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch[\"image\"], batch[\"label\"]\n",
    "        output = self.forward(images)\n",
    "        loss = self.loss_function(output, labels)\n",
    "        tensorboard_logs = {\"train_loss\": loss.item()}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch[\"image\"], batch[\"label\"]\n",
    "        roi_size = (160, 160, 160)\n",
    "        sw_batch_size = 4\n",
    "        outputs = sliding_window_inference(images, roi_size, sw_batch_size, self.forward)\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        outputs = [self.post_pred(i) for i in decollate_batch(outputs)]\n",
    "        labels = [self.post_label(i) for i in decollate_batch(labels)]\n",
    "        self.dice_metric(y_pred=outputs, y=labels)\n",
    "        d = {\"val_loss\": loss, \"val_number\": len(outputs)}\n",
    "        self.validation_step_outputs.append(d)\n",
    "        return d\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        val_loss, num_items = 0, 0\n",
    "        for output in self.validation_step_outputs:\n",
    "            val_loss += output[\"val_loss\"].sum().item()\n",
    "            num_items += output[\"val_number\"]\n",
    "        mean_val_dice = self.dice_metric.aggregate().item()\n",
    "        self.dice_metric.reset()\n",
    "        mean_val_loss = torch.tensor(val_loss / num_items)\n",
    "        tensorboard_logs = {\n",
    "            \"val_dice\": mean_val_dice,\n",
    "            \"val_loss\": mean_val_loss,\n",
    "        }\n",
    "        if mean_val_dice > self.best_val_dice:\n",
    "            self.best_val_dice = mean_val_dice\n",
    "            self.best_val_epoch = self.current_epoch\n",
    "        print(\n",
    "            f\"current epoch: {self.current_epoch} \"\n",
    "            f\"current mean dice: {mean_val_dice:.4f}\"\n",
    "            f\"\\nbest mean dice: {self.best_val_dice:.4f} \"\n",
    "            f\"at epoch: {self.best_val_epoch}\"\n",
    "        )\n",
    "        self.validation_step_outputs.clear()  # free memory\n",
    "        return {\"log\": tensorboard_logs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/pawel/Documents/RISA/3D_segmentation/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/pawel/Documents/RISA/3D_segmentation/.venv/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "  warn_deprecated(argname, msg, warning_category)\n",
      "Loading dataset: 100%|██████████| 32/32 [00:30<00:00,  1.05it/s]\n",
      "Loading dataset: 100%|██████████| 9/9 [00:06<00:00,  1.39it/s]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type     | Params\n",
      "-------------------------------------------\n",
      "0 | _model        | UNet     | 4.8 M \n",
      "1 | loss_function | DiceLoss | 0     \n",
      "-------------------------------------------\n",
      "4.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.8 M     Total params\n",
      "19.236    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]current epoch: 0 current mean dice: 0.0096\n",
      "best mean dice: 0.0096 at epoch: 0\n",
      "Epoch 0: 100%|██████████| 16/16 [00:07<00:00,  2.26it/s, v_num=142]        current epoch: 0 current mean dice: 0.0288\n",
      "best mean dice: 0.0288 at epoch: 0\n",
      "Epoch 1: 100%|██████████| 16/16 [00:06<00:00,  2.30it/s, v_num=142]current epoch: 1 current mean dice: 0.0356\n",
      "best mean dice: 0.0356 at epoch: 1\n",
      "Epoch 2: 100%|██████████| 16/16 [00:06<00:00,  2.29it/s, v_num=142]current epoch: 2 current mean dice: 0.0426\n",
      "best mean dice: 0.0426 at epoch: 2\n",
      "Epoch 3: 100%|██████████| 16/16 [00:07<00:00,  2.20it/s, v_num=142]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawel/Documents/RISA/3D_segmentation/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "# initialise the LightningModule\n",
    "net = Net()\n",
    "\n",
    "# set up loggers and checkpoints\n",
    "log_dir = os.path.join(root_dir, \"logs\")\n",
    "# tb_logger = pytorch_lightning.loggers.TensorBoardLogger(save_dir=log_dir)\n",
    "\n",
    "# initialise Lightning's trainer.\n",
    "trainer = pytorch_lightning.Trainer(\n",
    "    devices=[0],\n",
    "    max_epochs=600,\n",
    "    # logger=tb_logger,\n",
    "    enable_checkpointing=True,\n",
    "    num_sanity_val_steps=1,\n",
    "    log_every_n_steps=16,\n",
    ")\n",
    "\n",
    "# train\n",
    "trainer.fit(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if directory is None:\n",
    "    shutil.rmtree(root_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
