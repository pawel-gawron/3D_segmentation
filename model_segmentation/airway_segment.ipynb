{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from patchify import patchify\n",
    "\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nibabel.processing import resample_to_output\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/pawel/Documents/RISA/magisterka/segmentation_models.pytorch.3d')\n",
    "\n",
    "# print(sys.path)\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTDataset(Dataset):\n",
    "    def __init__(self, images_ct_scans, images_ct_masks, transform=None):\n",
    "        self.images_ct_scans = images_ct_scans\n",
    "        self.images_ct_masks = images_ct_masks\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_ct_scans)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_file = self.images_ct_scans[idx]\n",
    "\n",
    "        mask_file = self.images_ct_masks[idx]\n",
    "\n",
    "        print(image_file.shape[-1])\n",
    "\n",
    "        if self.transform is not None:\n",
    "            transformed_images = []\n",
    "            transformed_masks = []\n",
    "            for i in range(0, image_file.shape[-1]):\n",
    "                image_slice = image_file[..., i]\n",
    "\n",
    "                mask_slice = mask_file[..., i]\n",
    "                \n",
    "                image_slice = image_slice.astype(np.int16)\n",
    "                mask_slice = mask_slice.astype(np.uint8)\n",
    "\n",
    "                transformed = self.transform(image=image_slice, mask=mask_slice)\n",
    "\n",
    "                transformed_images.append(transformed[\"image\"])\n",
    "                transformed_masks.append(transformed[\"mask\"])\n",
    "\n",
    "            image_file = transformed_images\n",
    "            mask_file = transformed_masks\n",
    "        return image_file, mask_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.augmentations = A.Compose([\n",
    "        # A.ToFloat(max_value=1024+400, always_apply=True),\n",
    "        A.Resize(height=128, width=128),\n",
    "        # A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
    "        # A.RandomBrightnessContrast(p=0.5),\n",
    "        # A.Normalize(mean=[-1024/400], std=[1/400], always_apply=True),\n",
    "        A.ToFloat(max_value=255, always_apply=True),\n",
    "        ToTensorV2()\n",
    "        ])\n",
    "        self.transforms = A.Compose([\n",
    "        # A.ToFloat(max_value=1024+400, always_apply=True),\n",
    "        A.Resize(height=128, width=128),\n",
    "        # A.Normalize(mean=[-1024/400], std=[1/400], always_apply=True),\n",
    "        A.ToFloat(max_value=255, always_apply=True),\n",
    "        ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        self.test_dataset = None\n",
    "\n",
    "        self.ct_dataset= None\n",
    "\n",
    "        self.all_ct_scan_patches = []\n",
    "        self.all_ct_mask_patches = []\n",
    "\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.ct_dataset = load_dataset(\"andreped/AeroPath\")\n",
    "\n",
    "        print('len dataset', self.ct_dataset['test'].num_rows)\n",
    "\n",
    "        print(self.ct_dataset)\n",
    "\n",
    "        for index, img in enumerate(range(len(self.ct_dataset['test']))):\n",
    "            print(index)     #just stop here to see all file names printed\n",
    "                    \n",
    "            large_image = self.ct_dataset['test'][img]\n",
    "\n",
    "            ct_image = nib.load(large_image[\"ct\"])\n",
    "            ct_image = resample_to_output(ct_image, order=1)\n",
    "            ct_data_scan = ct_image.get_fdata().astype(\"int16\")\n",
    "            # ct_data_scan[ct_data_scan < -1024] = -1024\n",
    "            # ct_data_scan[ct_data_scan > 400] = 400\n",
    "\n",
    "            # ct_data_scan = ct_data_scan + 1024\n",
    "\n",
    "            ct_data_scan = np.clip(ct_data_scan, -1024, 400)\n",
    "            ct_data_scan += 1024\n",
    "\n",
    "            ct_mask = nib.load(large_image[\"airways\"])\n",
    "            ct_mask = resample_to_output(ct_mask, order=1)\n",
    "            ct_data_mask = ct_mask.get_fdata().astype(\"uint8\")\n",
    "                    \n",
    "            percent_size_x = 0.5  # Przykładowo 20% w osi X\n",
    "            percent_size_y = 0.5  # Przykładowo 20% w osi Y\n",
    "            fixed_size_z = 50  # Stała liczba sliców w osi Z\n",
    "\n",
    "            scan_shape = ct_data_scan.shape\n",
    "\n",
    "            patch_size_x = min(int(round(scan_shape[0] * percent_size_x)), scan_shape[0])\n",
    "            patch_size_y = min(int(round(scan_shape[1] * percent_size_y)), scan_shape[1])\n",
    "\n",
    "            patch_size = (patch_size_x, patch_size_y, fixed_size_z)\n",
    "\n",
    "            step = patch_size\n",
    "\n",
    "            patches_scan = patchify(ct_data_scan, patch_size, step=step)\n",
    "            patches_mask = patchify(ct_data_mask, patch_size, step=step)\n",
    "\n",
    "            print(\"TEST TEST TEST\")\n",
    "\n",
    "            # Pętle do iteracji przez otrzymane fragmenty danego skanu\n",
    "            for i in range(patches_scan.shape[0]):\n",
    "                for j in range(patches_scan.shape[1]):\n",
    "                    for k in range(patches_scan.shape[2]):\n",
    "                        patch_scan = patches_scan[i, j, k, :, :, :]\n",
    "                        patch_mask = patches_mask[i, j, k, :, :, :]\n",
    "                            \n",
    "                        self.all_ct_scan_patches.append(patch_scan)\n",
    "                        self.all_ct_mask_patches.append(patch_mask)\n",
    "\n",
    "        print(\"FINISHING PREPARE DATA\")\n",
    "\n",
    "    def setup(self):\n",
    "        # Split the data and assign datasets for use in dataloaders\n",
    "\n",
    "        all_indices = np.arange(len(self.all_ct_scan_patches))\n",
    "\n",
    "        self.all_ct_scan_patches = np.array(self.all_ct_scan_patches, dtype=object)\n",
    "        self.all_ct_mask_patches = np.array(self.all_ct_mask_patches, dtype=object)\n",
    "\n",
    "        train_index, val_index = train_test_split(all_indices, test_size = 0.3, random_state=42)\n",
    "        val_index, test_index = train_test_split(val_index, test_size = 0.5, random_state=42)\n",
    "\n",
    "        train_scans = self.all_ct_scan_patches[train_index]\n",
    "        train_masks = self.all_ct_mask_patches[train_index]\n",
    "\n",
    "        val_scans = self.all_ct_scan_patches[val_index]\n",
    "        val_masks = self.all_ct_mask_patches[val_index]\n",
    "\n",
    "        test_scans = self.all_ct_scan_patches[test_index]\n",
    "        test_masks = self.all_ct_mask_patches[test_index]\n",
    "\n",
    "        self.train_dataset = CTDataset(train_scans, train_masks, transform=self.augmentations)\n",
    "        self.val_dataset = CTDataset(val_scans, val_masks, transform=self.transforms)\n",
    "        self.test_dataset = CTDataset(test_scans, test_masks, transform=self.transforms)\n",
    "\n",
    "        print(\"FINISHING SETUP\")\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=2)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=2)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirWayModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, encoder_name: str):\n",
    "        super().__init__()\n",
    "        # self.model = smp.create_model(\n",
    "        #     arch, encoder_name=encoder_name, in_channels=in_channels, classes=out_classes, **kwargs\n",
    "        # )\n",
    "        self.model = smp.Unet_3D(\n",
    "            encoder_name=encoder_name)\n",
    "\n",
    "        self.loss_function = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
    "\n",
    "        metrics = torchmetrics.MetricCollection([\n",
    "            torchmetrics.F1Score(task='BINARY'),\n",
    "            torchmetrics.Precision(task='BINARY'),\n",
    "            torchmetrics.Recall(task='BINARY')\n",
    "        ])\n",
    "        self.train_metrics = metrics.clone('train_')\n",
    "        self.val_metrics = metrics.clone('val_')\n",
    "        self.test_metrics = metrics.clone('test_')\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        labels = torch.mean(labels, dim=1, keepdim=True)\n",
    "        outputs = self(inputs)\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "\n",
    "        # self.accuracy.update(outputs, labels)\n",
    "        # self.log('train_loss', loss, prog_bar=True)\n",
    "        # self.log('train_acc', self.accuracy, prog_bar=True)\n",
    "        # self.log('val_acc', self.validation_step, prog_bar=True)\n",
    "\n",
    "        self.train_metrics.update(outputs, labels)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log_dict(self.train_metrics)\n",
    "\n",
    "        # self.append(\"train/loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        labels = torch.mean(labels, dim=1, keepdim=True)\n",
    "        outputs = self(inputs)\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "\n",
    "        # self.accuracy.update(outputs, labels)\n",
    "\n",
    "        # self.log('val_loss', loss, prog_bar=True)\n",
    "        # self.log('val_acc', self.accuracy, prog_bar=True)\n",
    "\n",
    "        self.val_metrics.update(outputs, labels)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log_dict(self.val_metrics)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        labels = torch.mean(labels, dim=1, keepdim=True)\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "\n",
    "        # self.accuracy.update(outputs, labels)\n",
    "\n",
    "        # self.log('test_loss', loss)\n",
    "        # self.log('test_acc', self.accuracy)\n",
    "\n",
    "        self.test_metrics.update(outputs, labels)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log_dict(self.test_metrics)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Tym razem użyjmy optimizera Adam - uczenie powinno być szybsze\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len dataset 27\n",
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['ct', 'airways', 'lungs'],\n",
      "        num_rows: 27\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "CTDataModule.process_image() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\nTypeError: CTDataModule.process_image() takes 1 positional argument but 2 were given\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 12\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor = 'val_BinaryF1Score', mode='max', verbose = True)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# # logger = pl.loggers.NeptuneLogger(project=\"gawron.pawel1999/ZPO-Lab06\", api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI0MDE0NTRlMy03NDY2LTQ0OWYtYTcxMS1jMDE5OThlYjIyZjQifQ==\")\u001b[39;00m\n\u001b[1;32m     10\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m                      max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment_model_3D\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/RISA/magisterka/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/RISA/magisterka/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/Documents/RISA/magisterka/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/RISA/magisterka/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:947\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__setup_profiler()\n\u001b[1;32m    946\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: preparing data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 947\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    949\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_setup_hook(\u001b[38;5;28mself\u001b[39m)  \u001b[38;5;66;03m# allow user to set up LightningModule in accelerator environment\u001b[39;00m\n\u001b[1;32m    950\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: configuring model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/RISA/magisterka/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:94\u001b[0m, in \u001b[0;36m_DataConnector.prepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m     dm_prepare_data_per_node \u001b[38;5;241m=\u001b[39m datamodule\u001b[38;5;241m.\u001b[39mprepare_data_per_node\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (dm_prepare_data_per_node \u001b[38;5;129;01mand\u001b[39;00m local_rank_zero) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m dm_prepare_data_per_node \u001b[38;5;129;01mand\u001b[39;00m global_rank_zero):\n\u001b[0;32m---> 94\u001b[0m         \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_datamodule_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprepare_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# handle lightning module prepare data:\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# check for prepare_data_per_node before calling lightning_module.prepare_data\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/RISA/magisterka/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:179\u001b[0m, in \u001b[0;36m_call_lightning_datamodule_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn):\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningDataModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mdatamodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[37], line 76\u001b[0m, in \u001b[0;36mCTDataModule.prepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m step \u001b[38;5;241m=\u001b[39m patch_size\n\u001b[1;32m     74\u001b[0m pool \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mPool(mp\u001b[38;5;241m.\u001b[39mcpu_count())\n\u001b[0;32m---> 76\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mct_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m patches_scan, patches_mask \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_ct_scan_patches\u001b[38;5;241m.\u001b[39mextend(patches_scan)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mTypeError\u001b[0m: CTDataModule.process_image() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# segment_model_3D = AirWayModel(arch='unet_3d', encoder_name='tu-resnet10t', in_channels=1, out_classes=2, encoder_depth = 4, decoder_channels = (128, 64, 32, 16))\n",
    "segment_model_3D = AirWayModel(encoder_name='resnet18')\n",
    "\n",
    "data_module = CTDataModule()\n",
    "\n",
    "# checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor = 'val_BinaryF1Score', mode='max', verbose = True)\n",
    "\n",
    "# # logger = pl.loggers.NeptuneLogger(project=\"gawron.pawel1999/ZPO-Lab06\", api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI0MDE0NTRlMy03NDY2LTQ0OWYtYTcxMS1jMDE5OThlYjIyZjQifQ==\")\n",
    "\n",
    "trainer = pl.Trainer(accelerator='gpu',\n",
    "                     max_epochs=10)\n",
    "trainer.fit(segment_model_3D, datamodule = data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
