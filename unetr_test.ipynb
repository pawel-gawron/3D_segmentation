{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from monai.networks.nets import UNETR\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.data import CacheDataset, DataLoader, load_decathlon_datalist\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandFlipd,\n",
    "    RandRotate90d,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Resized,\n",
    ")\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, list_data_collate, decollate_batch, DataLoader\n",
    "from monai.losses import DiceLoss\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from monai.networks.nets import UNETR\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.data import CacheDataset, DataLoader, load_decathlon_datalist\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandFlipd,\n",
    "    RandRotate90d,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Resized,\n",
    "    EnsureType,\n",
    "    EnsureTyped,\n",
    "    CropForegroundd,\n",
    ")\n",
    "\n",
    "class MONAIUNETR3DSegmentation(pl.LightningModule):\n",
    "    def __init__(self, train_datalist, val_datalist, root_dir, batch_size=1, learning_rate=1e-4):\n",
    "        super(MONAIUNETR3DSegmentation, self).__init__()\n",
    "        self.train_datalist = train_datalist\n",
    "        self.val_datalist = val_datalist\n",
    "        self.root_dir = root_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self._model = UNETR(\n",
    "            in_channels=1,\n",
    "            out_channels=2,\n",
    "            img_size=(80, 80, 80),  # Updated to 80, 80, 80\n",
    "            feature_size=16,\n",
    "            hidden_size=768,\n",
    "            mlp_dim=3072,\n",
    "            num_heads=12,\n",
    "            pos_embed=\"perceptron\",\n",
    "            norm_name=\"instance\",\n",
    "            res_block=True,\n",
    "            dropout_rate=0.0,\n",
    "        )\n",
    "\n",
    "        self.loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "        self.post_pred = Compose([EnsureType(\"tensor\", device=\"cpu\"), AsDiscrete(argmax=True, to_onehot=2)])\n",
    "        self.post_label = Compose([EnsureType(\"tensor\", device=\"cpu\"), AsDiscrete(to_onehot=2)])\n",
    "        self.dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "        self.best_val_dice = 0\n",
    "        self.best_val_epoch = 0\n",
    "        self.validation_step_outputs = []\n",
    "        \n",
    "        self.roi_size = (80, 80, 80)\n",
    "\n",
    "\n",
    "        self.common_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"label\"]),\n",
    "            EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "            Spacingd(\n",
    "                keys=[\"image\", \"label\"],\n",
    "                # pixdim=(1.5, 1.5, 2.0),\n",
    "                pixdim=(1.1, 1.1, 1.40),\n",
    "                mode=(\"bilinear\", \"nearest\"),\n",
    "            ),\n",
    "            ScaleIntensityRanged(\n",
    "                keys=[\"image\"],\n",
    "                a_min=-1024,\n",
    "                a_max=1024,\n",
    "                b_min=0.0,\n",
    "                b_max=1.0,\n",
    "                clip=True,\n",
    "            ),\n",
    "            CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "            Resized(keys=[\"image\", \"label\"], spatial_size=(80, 80, 80)),\n",
    "            EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        ]\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self._model(x)\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        train_transforms = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "                Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "                Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                ScaleIntensityRanged(\n",
    "                keys=[\"image\"],\n",
    "                a_min=-1024,\n",
    "                a_max=1024,\n",
    "                b_min=0.0,\n",
    "                b_max=1.0,\n",
    "                clip=True,),\n",
    "                CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "                Resized(keys=[\"image\", \"label\"], spatial_size=(80, 80, 80), mode=(\"trilinear\", \"nearest\")),  # Ensure the size is (80, 80, 80)\n",
    "                EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "\n",
    "                # RandCropByPosNegLabeld(keys=[\"image\", \"label\"], label_key=\"label\", spatial_size=(80, 80, 80), pos=1, neg=1, num_samples=4, image_key=\"image\", image_threshold=0),\n",
    "                # RandFlipd(keys=[\"image\", \"label\"], spatial_axis=[0], prob=0.10),\n",
    "                # RandFlipd(keys=[\"image\", \"label\"], spatial_axis=[1], prob=0.10),\n",
    "                # RandFlipd(keys=[\"image\", \"label\"], spatial_axis=[2], prob=0.10),\n",
    "                # RandRotate90d(keys=[\"image\", \"label\"], prob=0.10, max_k=3),\n",
    "                # RandShiftIntensityd(keys=\"image\", offsets=0.10, prob=0.50),\n",
    "            ]\n",
    "        )\n",
    "        val_transforms = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "                ScaleIntensityRanged(\n",
    "                keys=[\"image\"],\n",
    "                a_min=-1024,\n",
    "                a_max=1024,\n",
    "                b_min=0.0,\n",
    "                b_max=1.0,\n",
    "                clip=True,),\n",
    "                Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "                CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "                Resized(keys=[\"image\", \"label\"], spatial_size=(80, 80, 80), mode=(\"trilinear\", \"nearest\")),  # Ensure the size is (80, 80, 80)\n",
    "\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.train_ds = CacheDataset(data=self.train_datalist, transform=train_transforms, cache_rate=1.0, num_workers=4)\n",
    "        self.val_ds = CacheDataset(data=self.val_datalist, transform=val_transforms, cache_rate=1.0, num_workers=4)\n",
    "\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self._model.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    # def training_step(self, batch, batch_idx):\n",
    "    #     images, labels = (batch[\"image\"].cuda(), batch[\"label\"].cuda())\n",
    "    #     output = self.forward(images)\n",
    "    #     loss = self.loss_function(output, labels)\n",
    "    #     tensorboard_logs = {\"train_loss\": loss.item()}\n",
    "    #     return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch[\"image\"], batch[\"label\"]\n",
    "        logits = self._model(images)\n",
    "        val_loss = self.loss_function(logits, labels)\n",
    "        self.dice_metric(y_pred=logits, y=labels)\n",
    "        self.log(\"val_loss\", val_loss, prog_bar=True)\n",
    "        return val_loss\n",
    "\n",
    "    # def validation_step(self, batch, batch_idx):\n",
    "    #     images, labels = batch[\"image\"], batch[\"label\"]\n",
    "    #     roi_size = self.roi_size\n",
    "    #     sw_batch_size = 4\n",
    "    #     outputs = sliding_window_inference(images, roi_size, sw_batch_size, self)\n",
    "    #     loss = self.loss_function(outputs, labels)\n",
    "    #     outputs = [self.post_pred(i) for i in decollate_batch(outputs)]\n",
    "    #     labels = [self.post_label(i) for i in decollate_batch(labels)]\n",
    "    #     self.dice_metric(y_pred=outputs, y=labels)\n",
    "    #     d = {\"val_loss\": loss, \"val_number\": len(outputs)}\n",
    "    #     self.validation_step_outputs.append(d)\n",
    "        # return d\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch[\"image\"], batch[\"label\"]\n",
    "        output = self.forward(images)\n",
    "        loss = self.loss_function(output, labels)\n",
    "        tensorboard_logs = {\"train_loss\": loss.item()}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    # def validation_step(self, batch, batch_idx):\n",
    "    #     images, labels = batch[\"image\"], batch[\"label\"]\n",
    "    #     roi_size = self.roi_size\n",
    "    #     sw_batch_size = 4\n",
    "    #     outputs = sliding_window_inference(images, roi_size, sw_batch_size, self)\n",
    "    #     loss = self.loss_function(outputs, labels)\n",
    "    #     outputs = [self.post_pred(i) for i in decollate_batch(outputs)]\n",
    "    #     labels = [self.post_label(i) for i in decollate_batch(labels)]\n",
    "    #     self.dice_metric(y_pred=outputs, y=labels)\n",
    "    #     d = {\"val_loss\": loss, \"val_number\": len(outputs)}\n",
    "    #     self.validation_step_outputs.append(d)\n",
    "    #     return d\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        dice_score = self.dice_metric.aggregate().item()\n",
    "        self.dice_metric.reset()\n",
    "        self.log(\"val_dice\", dice_score, prog_bar=True)\n",
    "        print(f\"Validation Dice Score: {dice_score:.4f}\")  # Print validation dice score\n",
    "\n",
    "        \n",
    "    # def on_validation_epoch_end(self):\n",
    "    #     val_loss, num_items = 0, 0\n",
    "    #     for output in self.validation_step_outputs:\n",
    "    #         val_loss += output[\"val_loss\"].sum().item()\n",
    "    #         num_items += output[\"val_number\"]\n",
    "    #     mean_val_dice = self.dice_metric.aggregate().item()\n",
    "    #     self.dice_metric.reset()\n",
    "    #     mean_val_loss = torch.tensor(val_loss / num_items)\n",
    "    #     tensorboard_logs = {\n",
    "    #         \"val_dice\": mean_val_dice,\n",
    "    #         \"val_loss\": mean_val_loss,\n",
    "    #     }\n",
    "    #     if mean_val_dice > self.best_val_dice:\n",
    "    #         self.best_val_dice = mean_val_dice\n",
    "    #         self.best_val_epoch = self.current_epoch\n",
    "    #     print(\n",
    "    #         f\"current epoch: {self.current_epoch} \"\n",
    "    #         f\"current mean dice: {mean_val_dice:.4f}\"\n",
    "    #         f\"\\nbest mean dice: {self.best_val_dice:.4f} \"\n",
    "    #         f\"at epoch: {self.best_val_epoch}\"\n",
    "    #     )\n",
    "    #     self.validation_step_outputs.clear()  # free memory\n",
    "    #     self.log('val_dice', mean_val_dice, on_step=False, on_epoch=True, prog_bar=True, logger=True) # log\n",
    "\n",
    "    #     return {\"log\": tensorboard_logs}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer setup with checkpointing\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath=\"checkpoints_unetr_test/\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_dice\",\n",
    "    mode=\"max\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "pattern = os.path.join('AeroPath', '**/*_CT_HR_label_airways.nii.gz')\n",
    "train_labels = sorted(glob.glob(pattern, recursive=True))\n",
    "\n",
    "pattern = os.path.join('AeroPath', '**/*_CT_HR.nii.gz')\n",
    "train_images = sorted(glob.glob(pattern, recursive=True))\n",
    "\n",
    "data_dicts = [\n",
    "    {\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(train_images, train_labels)\n",
    "]\n",
    "train_files, val_files = data_dicts[:-9], data_dicts[-9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# Define paths and datalists\n",
    "# train_datalist = load_decathlon_datalist(\"Task09_Spleen/dataset.json\", True, \"training\")\n",
    "# val_datalist = load_decathlon_datalist(\"Task09_Spleen/dataset.json\", True, \"validation\")\n",
    "root_dir = \"data/\"\n",
    "                                                                                                                                                                    \n",
    "# # Initialize the task\n",
    "# segmentation_task = MONAIUNETR3DSegmentation(train_datalist, val_datalist, root_dir)\n",
    "segmentation_task = MONAIUNETR3DSegmentation(train_files, val_files, root_dir)\n",
    "\n",
    "# Trainer setup\n",
    "trainer = pl.Trainer(max_epochs=100, callbacks=[checkpoint_callback])\n",
    "trainer.fit(segmentation_task)\n",
    "# torch.save(segmentation_task.state_dict(), 'unetr_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain completed, best_metric: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mnet\u001b[49m\u001b[38;5;241m.\u001b[39mbest_val_dice\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mat epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnet\u001b[38;5;241m.\u001b[39mbest_val_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the model for inference\n",
    "model = MONAIUNETR3DSegmentation(train_datalist, val_datalist, root_dir)\n",
    "model.load_state_dict(torch.load('unetr_model.pth'))\n",
    "model.eval()                                                                                                                                                                                    \n",
    "\n",
    "# Load new data for prediction\n",
    "test_datalist = load_decathlon_datalist(\"Task09_Spleen/dataset.json\", True, \"test\")\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        Spacingd(keys=[\"image\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\")),\n",
    "        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "        ScaleIntensityRanged(keys=\"image\", a_min=-175, a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
    "        Resized(keys=[\"image\"], spatial_size=(80, 80, 80), mode=\"trilinear\"),\n",
    "    ]\n",
    ")\n",
    "test_ds = CacheDataset(data=test_datalist, transform=test_transforms, cache_rate=1.0, num_workers=4)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        images = batch[\"image\"]\n",
    "        logits = model(images)\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        # Process the predictions as needed\n",
    "        print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = nib.load('Task09_Spleen/labelsTr/spleen_63.nii.gz')\n",
    "import numpy as np\n",
    "np.unique(label.get_fdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "# predictions = predictions.cpu().numpy()\n",
    "predictions = predictions[0, :, :, :]\n",
    "nib.save(nib.Nifti1Image(predictions.astype(float), nib.load('AeroPath/1/1_CT_HR_label_airways.nii.gz').affine), f'unetr_test_pred.nii.gz')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from monai.apps import download_and_extract\n",
    "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task09_Spleen.tar\"\n",
    "md5 = \"410d4a301da4e5b2f6f86ec3ddba524e\"\n",
    "\n",
    "compressed_file = os.path.join(os.getcwd(), \"Task09_Spleen.tar\")\n",
    "data_dir = os.path.join(os.getcwd(), \"Task09_Spleen\")\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
