{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.4.dev2427\n",
      "Numpy version: 1.26.4\n",
      "Pytorch version: 2.0.0+cu117\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: cbf90d0ddb27dc96a91385e4dd2f4eb239dea976\n",
      "MONAI __file__: /home/<username>/.local/lib/python3.10/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: 5.4.0\n",
      "Nibabel version: 5.2.1\n",
      "scikit-image version: 0.24.0\n",
      "scipy version: 1.14.0\n",
      "Pillow version: 10.4.0\n",
      "Tensorboard version: 2.12.2\n",
      "gdown version: 5.2.0\n",
      "TorchVision version: 0.15.1+cu117\n",
      "tqdm version: 4.66.4\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.8\n",
      "pandas version: 1.5.3\n",
      "einops version: 0.8.0\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: 1.0.0\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import jaccard_score\n",
    "from monai.utils import set_determinism\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Resized,\n",
    ")\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.data import (\n",
    "    ThreadDataLoader,\n",
    "    CacheDataset,\n",
    "    DataLoader,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    "    set_track_meta,\n",
    "    list_data_collate,\n",
    "    pad_list_data_collate,\n",
    ")\n",
    "import torch\n",
    "from dotenv import dotenv_values\n",
    "import neptune\n",
    "import dotenv\n",
    "from neptune.utils import stringify_unsupported\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(), 'AeroPath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpj5ez9caj\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.loggers import NeptuneLogger\n",
    "\n",
    "keys = dotenv_values(\".env\")\n",
    "api_key = keys[\"API_KEY\"]\n",
    "\n",
    "neptune_logger = NeptuneLogger(\n",
    "    project=\"aeropath-workspace/SwinUNETR\",\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys = dotenv_values(\".env\")\n",
    "# api_key = keys[\"API_KEY\"]\n",
    "\n",
    "# neptune_logger = pl.pytorch.loggers.NeptuneLogger(\n",
    "#     project=\"aeropath-workspace/airways-model\",\n",
    "#     api_key=api_key,\n",
    "#     tags=['aeropath', 'airways', 'monai', 'SwinUNETR', segment_name],\n",
    "#     name='airways-training'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_dice',\n",
    "    dirpath=os.path.join(data_dir, 'checkpoints'),  # Directory to save checkpoints\n",
    "    filename=segment_name +'_swin_unetr' '_{epoch:02d}-{val_dice:.4f}',  # Filename prefix for saving checkpoints\n",
    "    save_top_k=1,  # Save only the best checkpoint\n",
    "    mode='max',  # `min` for minimizing the metric, `max` for maximizing\n",
    "    verbose=True,  # Log a message when saving the best checkpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to download the pre-trained weights\n",
    "# !wget https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/model_swinvit.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'img_size': (160, 160, 160),\n",
    "    'in_channels': 1,\n",
    "    'out_channels': 2,\n",
    "    'feature_size':48,\n",
    "    'use_checkpoint': True,\n",
    "}\n",
    "\n",
    "weight = torch.load(\"./model_swinvit.pt\")\n",
    "\n",
    "class SwinUNetClass(pl.LightningModule):\n",
    "    def __init__(self, mode, roi_size, spatial_size):\n",
    "        super().__init__()\n",
    "        self._model = SwinUNETR(**parameters)\n",
    "        self._model.load_from(weights=weight)\n",
    "        self.loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "        self.post_pred = Compose([EnsureType(\"tensor\", device=\"cpu\"), AsDiscrete(argmax=True, to_onehot=2)])\n",
    "        self.post_label = Compose([EnsureType(\"tensor\", device=\"cpu\"), AsDiscrete(to_onehot=2)])\n",
    "        self.dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "        self.best_val_dice = 0\n",
    "        self.best_val_epoch = 0\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "        self.mode = mode\n",
    "        self.roi_size = roi_size\n",
    "        self.spatial_size = spatial_size\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._model(x)\n",
    "\n",
    "    def prepare_data(self, prepare_val_data=True, prepare_test_data=True):\n",
    "        # # set up the correct data path\n",
    "        def get_patterns(mode):\n",
    "            patterns = {\n",
    "                'whole': ('**/*_CT_HR_label_airways.nii.gz', '**/*_CT_HR.nii.gz'),\n",
    "                '1Q': ('nonoverlapping_labels/**/quadrant_1_*.nii.gz', 'nonoverlapping_quadrants/**/quadrant_1_*_CT_HR.nii.gz'),\n",
    "                '2Q': ('nonoverlapping_labels/**/quadrant_2_*.nii.gz', 'nonoverlapping_quadrants/**/quadrant_2_*_CT_HR.nii.gz'),\n",
    "                'left_bottom': ('dataset/airways_patched_4/**/*left_bottom_*.nii.gz', 'dataset/scan_patched_4/**/*left_bottom_*.nii.gz'),\n",
    "                'left_upper': ('dataset/airways_patched_4/**/*left_upper_*.nii.gz', 'dataset/scan_patched_4/**/*left_upper_*.nii.gz'),\n",
    "                'right_bottom': ('dataset/airways_patched_4/**/*right_bottom_*.nii.gz', 'dataset/scan_patched_4/**/*right_bottom_*.nii.gz'),\n",
    "                'right_upper': ('dataset/airways_patched_4/**/*right_upper_*.nii.gz', 'dataset/scan_patched_4/**/*right_upper_*.nii.gz')\n",
    "            }\n",
    "            return patterns.get(mode, (None, None))\n",
    "\n",
    "        pattern_labels, pattern_images = get_patterns(self.mode)\n",
    "        if pattern_labels and pattern_images:\n",
    "            train_labels = sorted(glob.glob(pattern_labels, recursive=True))\n",
    "            train_images = sorted(glob.glob(pattern_images, recursive=True))\n",
    "\n",
    "\n",
    "\n",
    "        data_dicts = [\n",
    "            {\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(train_images, train_labels)\n",
    "        ]\n",
    "        train_files, val_files = data_dicts[:-9], data_dicts[-9:]\n",
    "\n",
    "        # set deterministic training for reproducibility\n",
    "        set_determinism(seed=0)\n",
    "\n",
    "        # define the data transforms\n",
    "        num_samples = 2\n",
    "\n",
    "        train_transforms = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image\", \"label\"], ensure_channel_first=True),\n",
    "                ScaleIntensityRanged(\n",
    "                    keys=[\"image\"],\n",
    "                    a_min=-1024,\n",
    "                    a_max=1024,\n",
    "                    b_min=0.0,\n",
    "                    b_max=1.0,\n",
    "                    clip=True,\n",
    "                ),\n",
    "                CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "                Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                Spacingd(\n",
    "                    keys=[\"image\", \"label\"],\n",
    "                    pixdim=(1.0, 1.0, 1.35),\n",
    "                    mode=(\"bilinear\", \"nearest\"),\n",
    "                ),\n",
    "                EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "                # Resized(keys=[\"image\", \"label\"], spatial_size=self.spatial_size),\n",
    "                RandCropByPosNegLabeld(\n",
    "                    keys=[\"image\", \"label\"],\n",
    "                    label_key=\"label\",\n",
    "                    spatial_size=(64, 64, 64),\n",
    "                    pos=1,\n",
    "                    neg=1,\n",
    "                    num_samples=num_samples,\n",
    "                    image_key=\"image\",\n",
    "                    image_threshold=0,\n",
    "                ),\n",
    "                # RandFlipd(\n",
    "                #     keys=[\"image\", \"label\"],\n",
    "                #     spatial_axis=[0],\n",
    "                #     prob=0.10,\n",
    "                # ),\n",
    "                # RandFlipd(\n",
    "                #     keys=[\"image\", \"label\"],\n",
    "                #     spatial_axis=[1],\n",
    "                #     prob=0.10,\n",
    "                # ),\n",
    "                # RandFlipd(\n",
    "                #     keys=[\"image\", \"label\"],\n",
    "                #     spatial_axis=[2],\n",
    "                #     prob=0.10,\n",
    "                # ),\n",
    "                # RandRotate90d(\n",
    "                #     keys=[\"image\", \"label\"],\n",
    "                #     prob=0.10,\n",
    "                #     max_k=3,\n",
    "                # ),\n",
    "                RandShiftIntensityd(\n",
    "                    keys=[\"image\"],\n",
    "                    offsets=0.10,\n",
    "                    prob=0.50,\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        val_transforms = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image\", \"label\"], ensure_channel_first=True),\n",
    "                ScaleIntensityRanged(keys=[\"image\"], a_min=-1024, a_max=1024, b_min=0.0, b_max=1.0, clip=True),\n",
    "                CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "                Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                Spacingd(\n",
    "                    keys=[\"image\", \"label\"],\n",
    "                    # pixdim=(1.0, 1.0, 1.35),\n",
    "                    pixdim=(0.5, 0.5, 0.75),\n",
    "                    mode=(\"bilinear\", \"nearest\"),\n",
    "                ),\n",
    "                EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "                # Resized(keys=[\"image\", \"label\"], spatial_size=self.spatial_size),\n",
    "            ]\n",
    "        )                    \n",
    "\n",
    "        if prepare_test_data:\n",
    "            self.train_ds = CacheDataset(\n",
    "                data=train_files,\n",
    "                transform=train_transforms,\n",
    "                cache_rate=1.0,\n",
    "                num_workers=8,\n",
    "            )\n",
    "        if prepare_val_data:\n",
    "            self.val_ds = CacheDataset(\n",
    "                data=val_files,\n",
    "                transform=val_transforms,\n",
    "                cache_rate=1.0,\n",
    "                num_workers=4,\n",
    "            )\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_loader = ThreadDataLoader(\n",
    "            self.train_ds,\n",
    "            batch_size=1,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "        )\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_loader = ThreadDataLoader(self.val_ds, batch_size=1, num_workers=4)\n",
    "        return val_loader\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self._model.parameters(), 1e-4, weight_decay=1e-5)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch[\"image\"], batch[\"label\"]\n",
    "        output = self.forward(images)\n",
    "        loss = self.loss_function(output, labels)\n",
    "        tensorboard_logs = {\"train_loss\": loss.item()}\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch[\"image\"].cuda(), batch[\"label\"].cuda()\n",
    "        roi_size = self.roi_size\n",
    "        sw_batch_size = 4\n",
    "        outputs = sliding_window_inference(images, roi_size, sw_batch_size, self)\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        outputs = [self.post_pred(i) for i in decollate_batch(outputs)]\n",
    "        labels = [self.post_label(i) for i in decollate_batch(labels)]\n",
    "        self.dice_metric(y_pred=outputs, y=labels)\n",
    "\n",
    "        outputs_np = [output.argmax(dim=0).cpu().numpy() for output in outputs]\n",
    "        labels_np = [label.argmax(dim=0).cpu().numpy() for label in labels]\n",
    "        iou = np.mean([jaccard_score(ln.flatten(), on.flatten(), average='macro') for ln, on in zip(labels_np, outputs_np)])\n",
    "\n",
    "        d = {\"val_loss\": loss, \"val_number\": len(outputs), \"iou\": iou}\n",
    "        self.validation_step_outputs.append(d)\n",
    "        return d\n",
    "    \n",
    "\n",
    "    \n",
    "    def perform_inference(self, model, data):\n",
    "        # Perform inference using the model\n",
    "        with torch.no_grad():\n",
    "            data = torch.DoubleTensor(data)  # Convert data to type Double\n",
    "            model_output = model(data.unsqueeze(0))\n",
    "        return model_output\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        val_loss, num_items, total_iou = 0, 0, 0\n",
    "        for output in self.validation_step_outputs:\n",
    "            val_loss += output[\"val_loss\"].sum().item()\n",
    "            num_items += output[\"val_number\"]\n",
    "            total_iou += output[\"iou\"] * output[\"val_number\"]\n",
    "        mean_val_dice = self.dice_metric.aggregate().item()\n",
    "        mean_val_iou = total_iou / num_items\n",
    "        self.dice_metric.reset()\n",
    "        mean_val_loss = torch.tensor(val_loss / num_items)\n",
    "        tensorboard_logs = {\n",
    "            \"val_dice\": mean_val_dice,\n",
    "            \"val_loss\": mean_val_loss,\n",
    "            \"val_iou\": mean_val_iou,\n",
    "        }\n",
    "        if mean_val_dice > self.best_val_dice:\n",
    "            self.best_val_dice = mean_val_dice\n",
    "            self.best_val_epoch = self.current_epoch\n",
    "        print(\n",
    "            f\"current epoch: {self.current_epoch} \"\n",
    "            f\"current mean dice: {mean_val_dice:.4f} \"\n",
    "            f\"current mean iou: {mean_val_iou:.4f}\"\n",
    "            f\"\\nbest mean dice: {self.best_val_dice:.4f} \"\n",
    "            f\"at epoch: {self.best_val_epoch}\"\n",
    "        )\n",
    "        self.validation_step_outputs.clear()\n",
    "        self.log('val_dice', mean_val_dice, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('val_loss', mean_val_loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log('val_iou', mean_val_iou, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "\n",
    "        return {\"log\": tensorboard_logs}\n",
    "    \n",
    "    \n",
    "    def dice_score(self, prediction_tensor, label_tensor):\n",
    "        # Compute Dice score\n",
    "        dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "        dice_metric(y_pred=prediction_tensor, y=label_tensor)\n",
    "        dice_score = dice_metric.aggregate().item()\n",
    "        dice_metric.reset()\n",
    "\n",
    "        print(dice_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.networks.nets.swin_unetr SwinUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n"
     ]
    }
   ],
   "source": [
    "# segment_name = \"left_upper\"\n",
    "# segment_name = \"right_upper\"\n",
    "# segment_name = \"right_bottom\"\n",
    "# segment_name = \"left_bottom\"\n",
    "segment_name = \"whole\"\n",
    "# segment_name = \"2Q\"\n",
    "\n",
    "\n",
    "Net_segment       = SwinUNetClass(mode = segment_name,       roi_size=[64, 64, 64],   spatial_size=(160, 160, 160))\n",
    "# NetWhole          = SwinUNetClass(mode = 'whole',            roi_size=(32, 32, 32),   spatial_size=(160, 160, 160))\n",
    "# Net1Q             = SwinUNetClass(mode = '1Q',               roi_size=(160*2, 160, 160), spatial_size=(160*2, 160, 160))\n",
    "# Net2Q             = SwinUNetClass(mode = '2Q',               roi_size=(160*2, 160, 160), spatial_size=(160*2, 160, 160))\n",
    "\n",
    "# NetWhole    = UNetClass(mode = 'whole', roi_size=(192, 192, 212),   spatial_size=(192, 192, 212))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: The following monitoring options are disabled by default in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', and 'capture_hardware_metrics'. To enable them, set each parameter to 'True' when initializing the run. The monitoring will continue until you call run.stop() or the kernel stops. Also note: Your source files can only be tracked if you pass the path(s) to the 'source_code' argument. For help, see the Neptune docs: https://docs.neptune.ai/logging/source_code/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/aeropath-workspace/SwinUNETR/e/SWIN-6\n"
     ]
    }
   ],
   "source": [
    "neptune_logger.experiment[\"model/parameters\"] = stringify_unsupported(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "Loading dataset:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "net = Net_segment\n",
    "net.prepare_data(prepare_val_data=True, prepare_test_data=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(332, 332, 115)\n",
      "(324, 293, 107)\n",
      "(324, 293, 107)\n",
      "(387, 387, 134)\n",
      "(387, 387, 135)\n",
      "(376, 376, 99)\n",
      "(376, 376, 100)\n",
      "(385, 385, 135)\n",
      "(385, 385, 135)\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "for idx, data in enumerate(net.val_ds):\n",
    "    image, label = data['image'], data['label']\n",
    "    image, label = image[0, ...].numpy(), label[0, ...].numpy()\n",
    "\n",
    "    print(image.shape)\n",
    "\n",
    "    nib.save(nib.Nifti1Image(label.astype(float), nib.load('AeroPath/1/1_CT_HR_label_airways.nii.gz').affine), os.path.join('val_test', f'{idx}.nii.gz'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "Loading dataset:   0%|          | 0/72 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# initialise the LightningModule\n",
    "# net = Net1Q\n",
    "# net = Net2Q\n",
    "net = Net_segment\n",
    "# net = NetWhole\n",
    "# set up loggers and checkpoints\n",
    "log_dir = os.path.join(root_dir, \"logs\")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_dice',\n",
    "    patience=10,\n",
    "    verbose=True,        \n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "# initialise Lightning's trainer.\n",
    "trainer = pl.Trainer(\n",
    "    devices=[0],\n",
    "    max_epochs=600,\n",
    "    logger=neptune_logger,\n",
    "    enable_checkpointing=True,\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "    num_sanity_val_steps=1,\n",
    "    log_every_n_steps=16,\n",
    ")\n",
    "# train\n",
    "trainer.fit(net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
