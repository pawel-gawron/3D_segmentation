{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTe3HtVqI0vM"
      },
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igaMSdU8I0vM",
        "outputId": "fbf973c9-5926-4875-cda6-903844ab9f9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: python: command not found\n",
            "/bin/bash: line 1: python: command not found\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/gasyna/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
            "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
          ]
        }
      ],
      "source": [
        "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel]\"\n",
        "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
        "!pip install -q pytorch-lightning~=2.0\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7oM0xTwI0vN"
      },
      "source": [
        "## Setup imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7HEKxFEKI0vN",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MONAI version: 1.4.dev2425\n",
            "Numpy version: 1.26.4\n",
            "Pytorch version: 2.3.1+cu121\n",
            "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
            "MONAI rev id: b5d71491b839191430b236bd3b233c5f29daf229\n",
            "MONAI __file__: /home/<username>/Documents/RISA/3D_segmentation/.venv/lib/python3.10/site-packages/monai/__init__.py\n",
            "\n",
            "Optional dependencies:\n",
            "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "Nibabel version: 5.2.1\n",
            "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "scipy version: 1.14.0\n",
            "Pillow version: 10.3.0\n",
            "Tensorboard version: 2.17.0\n",
            "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "TorchVision version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "tqdm version: 4.66.4\n",
            "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "psutil version: 6.0.0\n",
            "pandas version: 2.2.2\n",
            "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "\n",
            "For details about installing the optional dependencies, please visit:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pytorch_lightning\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from monai.utils import set_determinism\n",
        "from monai.transforms import (\n",
        "AsDiscrete,\n",
        "EnsureChannelFirstd,\n",
        "Compose,\n",
        "CropForegroundd,\n",
        "LoadImaged,\n",
        "Orientationd,\n",
        "RandCropByPosNegLabeld,\n",
        "ScaleIntensityRanged,\n",
        "Spacingd,\n",
        "EnsureType,\n",
        "EnsureTyped,\n",
        "Resized,\n",
        "RandAdjustContrastd, \n",
        "RandFlipd, \n",
        "RandAffined, \n",
        "RandAdjustContrastd\n",
        "\n",
        ")\n",
        "from monai.networks.nets import UNet, UNETR\n",
        "from monai.networks.layers import Norm\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.losses import DiceLoss\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.data import CacheDataset, list_data_collate, decollate_batch, DataLoader\n",
        "from monai.config import print_config\n",
        "from monai.apps import download_and_extract\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "import shutil\n",
        "import os\n",
        "import glob\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from natsort import natsorted\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import jaccard_score\n",
        "from neptune.utils import stringify_unsupported\n",
        "\n",
        "\n",
        "print_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzzE3GGNI0vO"
      },
      "source": [
        "## Setup data directory\n",
        "\n",
        "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.  \n",
        "This allows you to save results and reuse downloads.  \n",
        "If not specified a temporary directory will be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1f_XjbPrI0vO",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/tmp/tmp2kqr5w_p\n"
          ]
        }
      ],
      "source": [
        "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
        "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
        "print(root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = os.path.join(os.getcwd(), 'AeroPath')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YTzgAPbI0vP"
      },
      "source": [
        "## Download dataset\n",
        "\n",
        "Downloads and extracts the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "resource = \"https://zenodo.org/records/10069289/files/AeroPath.zip?download=1\"\n",
        "md5 = \"3fd5106c175c85d60eaece220f5dfd87\"\n",
        "\n",
        "compressed_file = os.path.join(root_dir, \"AeroPath.zip\")\n",
        "if not os.path.exists(data_dir):\n",
        "    download_and_extract(resource, compressed_file, root_dir, md5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neptune logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "api_key = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlMjFlODRjYi05ZGU2LTQzMDEtOTcwOS1mNWUxNGQxOTdjMmQifQ==\"\n",
        "\n",
        "neptune_logger = pytorch_lightning.loggers.NeptuneLogger(\n",
        "    project=\"aeropath-workspace/airways-model\",\n",
        "    api_key=api_key,\n",
        "    tags=['aeropath', 'airways', 'monai'],\n",
        "    name='airways-training'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "segment_name = \"left_upper\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='val_dice',\n",
        "    dirpath=os.path.join(data_dir, 'checkpoints'),  # Directory to save checkpoints\n",
        "    filename=segment_name + '_{epoch:02d}-{val_dice:.4f}',  # Filename prefix for saving checkpoints\n",
        "    save_top_k=1,  # Save only the best checkpoint\n",
        "    mode='max',  # `min` for minimizing the metric, `max` for maximizing\n",
        "    verbose=True,  # Log a message when saving the best checkpoint\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSQVxGHhI0vQ"
      },
      "source": [
        "## Define the LightningModule\n",
        "\n",
        "The LightningModule contains a refactoring of your training code. The following module is a refactoring of the code in `spleen_segmentation_3d.ipynb`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1-m7FfcI0vQ"
      },
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    'spatial_dims': 3,\n",
        "    'in_channels': 1,\n",
        "    'out_channels': 2,\n",
        "    'channels': (16, 32, 64, 128, 256),\n",
        "    'strides': (2, 2, 2, 2),\n",
        "    'num_res_units': 2,\n",
        "    'norm': Norm.BATCH\n",
        "}\n",
        "\n",
        "\n",
        "class UNetClass(pytorch_lightning.LightningModule):\n",
        "    def __init__(self, mode, roi_size, spatial_size):\n",
        "        super().__init__()\n",
        "        self._model = UNet(**parameters)\n",
        "        self.loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
        "        self.post_pred = Compose([EnsureType(\"tensor\", device=\"cpu\"), AsDiscrete(argmax=True, to_onehot=2)])\n",
        "        self.post_label = Compose([EnsureType(\"tensor\", device=\"cpu\"), AsDiscrete(to_onehot=2)])\n",
        "        self.dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
        "        self.best_val_dice = 0\n",
        "        self.best_val_epoch = 0\n",
        "        self.validation_step_outputs = []\n",
        "\n",
        "        self.mode = mode\n",
        "        self.roi_size = roi_size\n",
        "        self.spatial_size = spatial_size\n",
        "\n",
        "        # self.common_transforms = Compose(\n",
        "        # [\n",
        "        #     LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        #     EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "        #     Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "        #     Spacingd(\n",
        "        #         keys=[\"image\", \"label\"],\n",
        "        #         # pixdim=(1.5, 1.5, 2.0),\n",
        "        #         pixdim=(0.75, 0.75, 0.75),\n",
        "        #         mode=(\"bilinear\", \"nearest\"),\n",
        "        #     ),\n",
        "        #     ScaleIntensityRanged(\n",
        "        #         keys=[\"image\"],\n",
        "        #         a_min=-1024,\n",
        "        #         a_max=1024,\n",
        "        #         b_min=0.0,\n",
        "        #         b_max=1.0,\n",
        "        #         clip=True,\n",
        "        #     ),\n",
        "        #     CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
        "        #     Resized(keys=[\"image\", \"label\"], spatial_size=self.spatial_size),\n",
        "\n",
        "        #     EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "        # ]\n",
        "        # )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._model(x)\n",
        "\n",
        "    def prepare_data(self, prepare_val_data=True, prepare_test_data=True):\n",
        "        # # set up the correct data path\n",
        "        def get_patterns(mode):\n",
        "            patterns = {\n",
        "                'whole': ('**/*_CT_HR_label_airways.nii.gz', '**/*_CT_HR.nii.gz'),\n",
        "                '1Q': ('nonoverlapping_labels/**/quadrant_1_*.nii.gz', 'nonoverlapping_quadrants/**/quadrant_1_*_CT_HR.nii.gz'),\n",
        "                '2Q': ('nonoverlapping_labels/**/quadrant_1_*.nii.gz', 'nonoverlapping_quadrants/**/quadrant_1_*_CT_HR.nii.gz'),\n",
        "                'left_bottom': ('dataset/airways_patched_4/**/*left_bottom_*.nii.gz', 'dataset/scan_patched_4/**/*left_bottom_*.nii.gz'),\n",
        "                'left_upper': ('dataset/airways_patched_4/**/*left_upper_*.nii.gz', 'dataset/scan_patched_4/**/*left_bottom_*.nii.gz'),\n",
        "                'right_bottom': ('dataset/airways_patched_4/**/*right_bottom_*.nii.gz', 'dataset/scan_patched_4/**/*left_bottom_*.nii.gz'),\n",
        "                'right_upper': ('dataset/airways_patched_4/**/*right_upper_*.nii.gz', 'dataset/scan_patched_4/**/*left_bottom_*.nii.gz')\n",
        "            }\n",
        "            return patterns.get(mode, (None, None))\n",
        "\n",
        "        pattern_labels, pattern_images = get_patterns(self.mode)\n",
        "        if pattern_labels and pattern_images:\n",
        "            train_labels = sorted(glob.glob(os.path.join(data_dir, pattern_labels), recursive=True))\n",
        "            train_images = sorted(glob.glob(os.path.join(data_dir, pattern_images), recursive=True))\n",
        "\n",
        "\n",
        "\n",
        "        data_dicts = [\n",
        "            {\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(train_images, train_labels)\n",
        "        ]\n",
        "        train_files, val_files = data_dicts[:-9], data_dicts[-9:]\n",
        "\n",
        "        # set deterministic training for reproducibility\n",
        "        set_determinism(seed=0)\n",
        "\n",
        "        # define the data transforms\n",
        "        train_transforms = Compose(\n",
        "            [\n",
        "                LoadImaged(keys=[\"image\", \"label\"]),\n",
        "                EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "                Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "                Spacingd(\n",
        "                    keys=[\"image\", \"label\"],\n",
        "                    # pixdim=(1.5, 1.5, 2.0),\n",
        "                    pixdim=(1.0, 1.0, 1.35),\n",
        "                    mode=(\"bilinear\", \"nearest\"),\n",
        "                ),\n",
        "                ScaleIntensityRanged(\n",
        "                    keys=[\"image\"],\n",
        "                    a_min=-1024,\n",
        "                    a_max=1024,\n",
        "                    b_min=0.0,\n",
        "                    b_max=1.0,\n",
        "                    clip=True,\n",
        "                ),\n",
        "                CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
        "                # Resized(keys=[\"image\", \"label\"], spatial_size=self.spatial_size),\n",
        "                # randomly crop out patch samples from\n",
        "                # big image based on pos / neg ratio\n",
        "                # the image centers of negative samples\n",
        "                # must be in valid image area\n",
        "                RandCropByPosNegLabeld(\n",
        "                    keys=[\"image\", \"label\"],\n",
        "                    label_key=\"label\",\n",
        "                    spatial_size=(64, 64, 64),\n",
        "                    pos=1,\n",
        "                    neg=1,\n",
        "                    num_samples=4,\n",
        "                    image_key=\"image\",\n",
        "                    image_threshold=0,\n",
        "                ),\n",
        "\n",
        "                # user can also add other random transforms\n",
        "                #                 RandAffined(\n",
        "                #                     keys=['image', 'label'],\n",
        "                #                     mode=('bilinear', 'nearest'),\n",
        "                #                     prob=1.0,\n",
        "                #                     spatial_size=(96, 96, 96),\n",
        "                #                     rotate_range=(0, 0, np.pi/15),\n",
        "                #                     scale_range=(0.1, 0.1, 0.1)),\n",
        "                # Adding the data augmentation transforms with a probability of 50%\n",
        "                # RandFlipd(\n",
        "                #     keys=[\"image\", \"label\"],\n",
        "                #     spatial_axis=[0],  # Horizontal flip\n",
        "                #     prob=0.5\n",
        "                # ),\n",
        "                # RandFlipd(\n",
        "                #     keys=[\"image\", \"label\"],\n",
        "                #     spatial_axis=[1],  # Vertical flip\n",
        "                #     prob=0.5\n",
        "                # ),\n",
        "                # RandAffined(\n",
        "                #     keys=[\"image\", \"label\"],\n",
        "                #     prob=0.5,\n",
        "                #     rotate_range=(np.deg2rad(20), np.deg2rad(20), np.deg2rad(20)),\n",
        "                #     translate_range=(0.2, 0.2, 0.2),\n",
        "                #     scale_range=(0.5, 1.5),\n",
        "                #     mode=('bilinear', 'nearest')\n",
        "                # ),\n",
        "                RandAdjustContrastd(\n",
        "                    keys=[\"image\"],\n",
        "                    gamma=(0.5, 2.0),\n",
        "                    prob=0.0\n",
        "                ),\n",
        "                EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "            ]\n",
        "        )\n",
        "        val_transforms = Compose(\n",
        "            [\n",
        "                LoadImaged(keys=[\"image\", \"label\"]),\n",
        "                EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "                Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "                Spacingd(\n",
        "                    keys=[\"image\", \"label\"],\n",
        "                    # pixdim=(1.5, 1.5, 2.0),\n",
        "                    pixdim=(1.0, 1.0, 1.35),\n",
        "                    mode=(\"bilinear\", \"nearest\"),\n",
        "                ),\n",
        "                ScaleIntensityRanged(\n",
        "                    keys=[\"image\"],\n",
        "                    a_min=-1024,\n",
        "                    a_max=1024,\n",
        "                    b_min=0.0,\n",
        "                    b_max=1.0,\n",
        "                    clip=True,\n",
        "                ),\n",
        "                Resized(keys=[\"image\", \"label\"], spatial_size=self.spatial_size),\n",
        "                CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
        "            ]\n",
        "        )\n",
        "                    \n",
        "\n",
        "        # we use cached datasets - these are 10x faster than regular datasets\n",
        "        if prepare_test_data:\n",
        "            self.train_ds = CacheDataset(\n",
        "                data=train_files,\n",
        "                transform=train_transforms,\n",
        "                cache_rate=1.0,\n",
        "                num_workers=4,\n",
        "            )\n",
        "        if prepare_val_data:\n",
        "            self.val_ds = CacheDataset(\n",
        "                data=val_files,\n",
        "                transform=val_transforms,\n",
        "                cache_rate=1.0,\n",
        "                num_workers=4,\n",
        "            )\n",
        "\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        train_loader = DataLoader(\n",
        "            self.train_ds,\n",
        "            batch_size=2,\n",
        "            shuffle=True,\n",
        "            num_workers=4,\n",
        "            collate_fn=list_data_collate,\n",
        "        )\n",
        "        return train_loader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        val_loader = DataLoader(self.val_ds, batch_size=1, num_workers=4)\n",
        "        return val_loader\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self._model.parameters(), 1e-4)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        images, labels = batch[\"image\"], batch[\"label\"]\n",
        "        output = self.forward(images)\n",
        "        loss = self.loss_function(output, labels)\n",
        "        tensorboard_logs = {\"train_loss\": loss.item()}\n",
        "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
        "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
        "\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        images, labels = batch[\"image\"], batch[\"label\"]\n",
        "        roi_size = self.roi_size\n",
        "        sw_batch_size = 4\n",
        "        outputs = sliding_window_inference(images, roi_size, sw_batch_size, self)\n",
        "        loss = self.loss_function(outputs, labels)\n",
        "        outputs = [self.post_pred(i) for i in decollate_batch(outputs)]\n",
        "        labels = [self.post_label(i) for i in decollate_batch(labels)]\n",
        "        self.dice_metric(y_pred=outputs, y=labels)\n",
        "\n",
        "        outputs_np = [output.argmax(dim=0).cpu().numpy() for output in outputs]\n",
        "        labels_np = [label.argmax(dim=0).cpu().numpy() for label in labels]\n",
        "        iou = np.mean([jaccard_score(ln.flatten(), on.flatten(), average='macro') for ln, on in zip(labels_np, outputs_np)])\n",
        "\n",
        "        d = {\"val_loss\": loss, \"val_number\": len(outputs), \"iou\": iou}\n",
        "        self.validation_step_outputs.append(d)\n",
        "        return d\n",
        "    \n",
        "\n",
        "    \n",
        "    def perform_inference(self, model, data):\n",
        "        # Perform inference using the model\n",
        "        with torch.no_grad():\n",
        "            data = torch.DoubleTensor(data)  # Convert data to type Double\n",
        "            model_output = model(data.unsqueeze(0))\n",
        "        return model_output\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        val_loss, num_items, total_iou = 0, 0, 0\n",
        "        for output in self.validation_step_outputs:\n",
        "            val_loss += output[\"val_loss\"].sum().item()\n",
        "            num_items += output[\"val_number\"]\n",
        "            total_iou += output[\"iou\"] * output[\"val_number\"]\n",
        "        mean_val_dice = self.dice_metric.aggregate().item()\n",
        "        mean_val_iou = total_iou / num_items\n",
        "        self.dice_metric.reset()\n",
        "        mean_val_loss = torch.tensor(val_loss / num_items)\n",
        "        tensorboard_logs = {\n",
        "            \"val_dice\": mean_val_dice,\n",
        "            \"val_loss\": mean_val_loss,\n",
        "            \"val_iou\": mean_val_iou,\n",
        "        }\n",
        "        if mean_val_dice > self.best_val_dice:\n",
        "            self.best_val_dice = mean_val_dice\n",
        "            self.best_val_epoch = self.current_epoch\n",
        "        print(\n",
        "            f\"current epoch: {self.current_epoch} \"\n",
        "            f\"current mean dice: {mean_val_dice:.4f} \"\n",
        "            f\"current mean iou: {mean_val_iou:.4f}\"\n",
        "            f\"\\nbest mean dice: {self.best_val_dice:.4f} \"\n",
        "            f\"at epoch: {self.best_val_epoch}\"\n",
        "        )\n",
        "        self.validation_step_outputs.clear()  # free memory\n",
        "        self.log('val_dice', mean_val_dice, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.log('val_loss', mean_val_loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
        "        self.log('val_iou', mean_val_iou, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
        "\n",
        "        return {\"log\": tensorboard_logs}\n",
        "    \n",
        "    \n",
        "    def dice_score(self, prediction_tensor, label_tensor):\n",
        "        # Compute Dice score\n",
        "        dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
        "        dice_metric(y_pred=prediction_tensor, y=label_tensor)\n",
        "        dice_score = dice_metric.aggregate().item()\n",
        "        dice_metric.reset()\n",
        "\n",
        "        print(dice_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Net_segment       = UNetClass(mode = segment_name,       roi_size=(160*2, 160, 160),   spatial_size=(160*2, 160, 160))\n",
        "NetWhole          = UNetClass(mode = 'whole',            roi_size=(128, 128, 144),   spatial_size=(128, 128, 144))\n",
        "Net1Q             = UNetClass(mode = '1Q',               roi_size=(160*2, 160, 160), spatial_size=(160*2, 160, 160))\n",
        "Net2Q             = UNetClass(mode = '2Q',               roi_size=(160*2, 160, 160), spatial_size=(160*2, 160, 160))\n",
        "\n",
        "# NetWhole    = UNetClass(mode = 'whole', roi_size=(192, 192, 212),   spatial_size=(192, 192, 212))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Log model parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/aeropath-workspace/airways-model/e/AIR-44\n"
          ]
        }
      ],
      "source": [
        "neptune_logger.experiment[\"model/parameters\"] = stringify_unsupported(parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSVCubC2I0vR"
      },
      "source": [
        "## Run the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Y8BpsB6sI0vR",
        "scrolled": false,
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "/home/pawel/Documents/RISA/3D_segmentation/.venv/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
            "  warn_deprecated(argname, msg, warning_category)\n",
            "\n",
            "\u001b[A"
          ]
        }
      ],
      "source": [
        "# initialise the LightningModule\n",
        "# net = Net1Q\n",
        "# net = Net2Q\n",
        "net = Net_segment\n",
        "# net = NetWhole\n",
        "# set up loggers and checkpoints\n",
        "log_dir = os.path.join(root_dir, \"logs\")\n",
        "tb_logger = pytorch_lightning.loggers.TensorBoardLogger(save_dir=log_dir)\n",
        "\n",
        "# initialise Lightning's trainer.\n",
        "trainer = pytorch_lightning.Trainer(\n",
        "    devices=[0],\n",
        "    max_epochs=600,\n",
        "    logger=neptune_logger,\n",
        "    enable_checkpointing=True,\n",
        "    callbacks=[checkpoint_callback],\n",
        "    num_sanity_val_steps=1,\n",
        "    log_every_n_steps=16,\n",
        ")\n",
        "# train\n",
        "trainer.fit(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "2TucnezFI0vR",
        "outputId": "4e0a75d6-eb09-4989-bb2b-a2c6b1388edf",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train completed, best_metric: 0.7536 at epoch 540\n"
          ]
        }
      ],
      "source": [
        "print(f\"train completed, best_metric: {net.best_val_dice:.4f} \" f\"at epoch {net.best_val_epoch}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from monai.networks.nets import UNet\n",
        "\n",
        "\n",
        "# Load the model weights from the checkpoint file\n",
        "checkpoint_path = 'best-checkpoint.ckpt'\n",
        "model = Net1Q.load_from_checkpoint('1Q_clipped_resized128_128_144_roibest_metric: 0.2797 at epoch 495.ckpt', mode = '1Q', roi_size=(160*2, 160, 160), spatial_size=(160*2, 160, 160))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Ensembling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cba0TIqDI0vR"
      },
      "source": [
        "## View training in tensorboard\n",
        "\n",
        "Please uncomment the following cell to load tensorboard results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dteU4yMVI0vR",
        "outputId": "8aa4354d-4d1a-4e57-d50e-d9a6eb88db5f"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=$log_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtDZoq7ZI0vS"
      },
      "source": [
        "## Load model and create prediction files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading dataset: 100%|██████████| 9/9 [01:05<00:00,  7.26s/it]\n"
          ]
        }
      ],
      "source": [
        "net = Net1Q.load_from_checkpoint('1Q_clipped_resized128_128_144_roibest_metric: 0.2797 at epoch 495.ckpt',                  mode = '1Q',    roi_size=(160*2, 160, 160), spatial_size=(160*2, 160, 160))\n",
        "net = Net2Q.load_from_checkpoint('2Q_clipped_resized320_160_160.ckpt',                                                      mode = '2Q',    roi_size=(160*2, 160, 160), spatial_size=(160*2, 160, 160))\n",
        "net = NetWhole.load_from_checkpoint('whole_clipped_resized160_best_metric: 0.8211 at epoch 562.ckpt',                       mode = 'whole', roi_size=(128, 128, 144),   spatial_size=(128, 128, 144))\n",
        "\n",
        "net.prepare_data(prepare_test_data=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test validation dataset labels\n",
        "for i, val_data in enumerate(net.val_dataloader()):\n",
        "    label = val_data['label'].cpu().numpy()[0, 0, :, :, :]\n",
        "    nib.save(nib.Nifti1Image(label.astype(float), nib.load('AeroPath/1/1_CT_HR_label_airways.nii.gz').affine), f'labels_spacingd_10less/{i}.nii.gz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8pp1HWrqI0vS",
        "jupyter": {
          "outputs_hidden": true
        },
        "lines_to_next_cell": 2,
        "outputId": "c7388a09-ec21-44bb-9747-1f1c8d1f81f9",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# model = Net.load_from_checkpoint('checkpoints/best-checkpoint_whole_64_0.8023 at epoch: 427.ckpt')\n",
        "\n",
        "# model.eval()\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model.to(device)\n",
        "\n",
        "# if net is None:\n",
        "#     net = Net.load_from_checkpoint('checkpoints/best-checkpoint_whole_64_0.8023 at epoch: 427.ckpt')\n",
        "#     net.prepare_data()\n",
        "\n",
        "net.eval()\n",
        "device = torch.device(\"cuda:0\")\n",
        "net.to(device)\n",
        "with torch.no_grad():\n",
        "    for i, val_data in enumerate(net.val_dataloader()):\n",
        "        # roi_size = (64, 64, 64)\n",
        "        roi_size = net.roi_size\n",
        "        # roi_size = (128, 128, 144)\n",
        "        sw_batch_size = 4\n",
        "        val_outputs = sliding_window_inference(val_data[\"image\"].to(device), roi_size, sw_batch_size, net)\n",
        "        # plot the slice [:, :, 80]\n",
        "        # plt.figure(\"check\", (18, 6))\n",
        "        # plt.subplot(1, 3, 1)\n",
        "        # plt.title(f\"image {i}\")\n",
        "        # plt.imshow(val_data[\"image\"][0, 0, :, :, 80], cmap=\"gray\")\n",
        "        # plt.subplot(1, 3, 2)\n",
        "        # plt.title(f\"label {i}\")\n",
        "        # plt.imshow(val_data[\"label\"][0, 0, :, :, 80])\n",
        "        # plt.subplot(1, 3, 3)\n",
        "        # plt.title(f\"output {i}\")\n",
        "        pred = torch.argmax(val_outputs, dim=1).detach().cpu()\n",
        "        # plt.imshow(pred[0, :, :, 80])\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        pred_np = pred.cpu().numpy()[0, :, :, :]\n",
        "\n",
        "        # dir_name = 'whole_resized_roi160'\n",
        "        # dir_name = '1Q_resized_roi160'\n",
        "        # # dir_name = '1Q'\n",
        "        # # dir_name = '2Q'\n",
        "\n",
        "        dir_name = net.mode\n",
        "\n",
        "        nib.save(nib.Nifti1Image(pred_np.astype(float), nib.load('AeroPath/1/1_CT_HR_label_airways.nii.gz').affine), f'pred/{dir_name}/{i}.nii.gz')\n",
        "\n",
        "        # label = val_data['label'].cpu().numpy()[0, 0, :, :, :]\n",
        "        # nib.save(nib.Nifti1Image(label.astype(float), nib.load('AeroPath/1/1_CT_HR_label_airways.nii.gz').affine), f'labels_resized/{i}.nii.gz')\n",
        "\n",
        "        # print(f\"pred shape: {pred_np.shape}, label shape: {label.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interpolate, Concat and ensemble predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dice Score for whole prediction: 0.8429\n",
            "Dice Score for ensembled prediction: 0.8514\n",
            "**************************************************\n",
            "Dice Score for whole prediction: 0.7267\n",
            "Dice Score for ensembled prediction: 0.7223\n",
            "**************************************************\n",
            "Dice Score for whole prediction: 0.7134\n",
            "Dice Score for ensembled prediction: 0.7225\n",
            "**************************************************\n",
            "Dice Score for whole prediction: 0.8573\n",
            "Dice Score for ensembled prediction: 0.8615\n",
            "**************************************************\n",
            "Dice Score for whole prediction: 0.8257\n",
            "Dice Score for ensembled prediction: 0.8436\n",
            "**************************************************\n",
            "Dice Score for whole prediction: 0.7070\n",
            "Dice Score for ensembled prediction: 0.7301\n",
            "**************************************************\n",
            "Dice Score for whole prediction: 0.7620\n",
            "Dice Score for ensembled prediction: 0.7973\n",
            "**************************************************\n",
            "Dice Score for whole prediction: 0.6476\n",
            "Dice Score for ensembled prediction: 0.6588\n",
            "**************************************************\n",
            "Dice Score for whole prediction: 0.8258\n",
            "Dice Score for ensembled prediction: 0.8360\n",
            "**************************************************\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import nibabel as nib\n",
        "from monai.transforms import Compose, AsDiscrete\n",
        "from monai.metrics import DiceMetric\n",
        "\n",
        "def interpolate_predictions(predictions, target_shape):\n",
        "    # Ensure predictions tensor has 5 dimensions: (N, C, D, H, W)\n",
        "    predictions = torch.tensor(predictions).unsqueeze(0).unsqueeze(0)  # Add batch and channel dimensions\n",
        "\n",
        "    # Interpolate the predictions using nearest neighbor interpolation\n",
        "    interpolated_predictions = F.interpolate(predictions, size=target_shape, mode='nearest')\n",
        "    \n",
        "    # Remove batch and channel dimensions after interpolation\n",
        "    interpolated_predictions = interpolated_predictions.squeeze(0).squeeze(0).numpy()\n",
        "    \n",
        "    return interpolated_predictions\n",
        "\n",
        "# Function to calculate Dice score\n",
        "def calc_dice_score(pred, label):\n",
        "    post_pred = Compose([AsDiscrete(argmax=False, to_onehot=2)])\n",
        "    post_label = Compose([AsDiscrete(to_onehot=2)])\n",
        "\n",
        "    # Ensure the inputs have the correct dimensions\n",
        "    pred = torch.tensor(pred).unsqueeze(0).unsqueeze(0)\n",
        "    label = torch.tensor(label).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    prediction_tensor = post_pred(pred)\n",
        "    label_tensor = post_label(label)\n",
        "\n",
        "    # Compute Dice score\n",
        "    dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
        "    dice_metric(y_pred=prediction_tensor, y=label_tensor)\n",
        "\n",
        "    dice_score = dice_metric.aggregate().item()\n",
        "    dice_metric.reset()\n",
        "\n",
        "    return dice_score\n",
        "\n",
        "\n",
        "labels = natsorted(glob.glob('labels/*', recursive=True))\n",
        "\n",
        "\n",
        "# Example usage with NIfTI files\n",
        "\n",
        "for idx, _ in enumerate(labels):\n",
        "    label = nib.load(f'labels_resized/{idx}.nii.gz').get_fdata()\n",
        "    # whole = nib.load(f'pred/whole_resized_roi160/{idx}.nii.gz').get_fdata()\n",
        "    whole = nib.load(f'pred/whole/{idx}.nii.gz').get_fdata()\n",
        "\n",
        "    pred_1Q = nib.load(f'pred/1Q_resized_roi160/{idx}.nii.gz').get_fdata()\n",
        "    pred_2Q = nib.load(f'pred/2Q_resized_roi160/{idx}.nii.gz').get_fdata()\n",
        "\n",
        "\n",
        "    # Interpolate predictions to allow for concatenation\n",
        "\n",
        "    inter_pred_1Q = interpolate_predictions(pred_1Q, (*whole.shape[:-1], pred_1Q.shape[-1]))\n",
        "    inter_pred_2Q = interpolate_predictions(pred_2Q, (*whole.shape[:-1], pred_2Q.shape[-1]))\n",
        "\n",
        "\n",
        "    # Merge interpolated predictions along the last axis (z-axis)\n",
        "    merged = np.concatenate((inter_pred_1Q, inter_pred_2Q), axis=2)\n",
        "\n",
        "    # Interpolate predictions to match whole.shape\n",
        "\n",
        "    merged = interpolate_predictions(merged, whole.shape)\n",
        "\n",
        "    # Save the merged predictions as a NIfTI file\n",
        "    merged_nifti = nib.Nifti1Image(merged, nib.load('AeroPath/1/1_CT_HR.nii.gz').affine)\n",
        "    nib.save(merged_nifti, 'pred_test_merged.nii.gz')\n",
        "    # print(f'Merged shape: {merged.shape}')\n",
        "\n",
        "    # Perform ensembling using the maximum values\n",
        "    ensembled = np.maximum(merged, whole)\n",
        "    \n",
        "    ensembled[:5, :, :] = 0\n",
        "    ensembled[-5:, :, :] = 0\n",
        "    ensembled[:, :5, :] = 0\n",
        "    ensembled[:, -5:, :] = 0\n",
        "    ensembled[:, :, :5] = 0\n",
        "    ensembled[:, :, -5:] = 0\n",
        "\n",
        "    # Save the ensembled predictions as a NIfTI file\n",
        "    ensembled_nifti = nib.Nifti1Image(ensembled, nib.load('AeroPath/1/1_CT_HR.nii.gz').affine)\n",
        "    nib.save(ensembled_nifti, f'pred/ensembled/{idx}.nii.gz')\n",
        "\n",
        "    # Compute Dice score\n",
        "    # print(f'whole: {whole.shape}, label: {label.shape}')\n",
        "    dice_whole = calc_dice_score(whole, label)\n",
        "    print(f'Dice Score for whole prediction: {dice_whole:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "    dice_ensembled = calc_dice_score(ensembled, label)\n",
        "    print(f'Dice Score for ensembled prediction: {dice_ensembled:.4f}')\n",
        "\n",
        "    print('*'*50)\n",
        "\n",
        "# Dice Score for whole prediction: 0.8711\n",
        "# Dice Score for ensembled prediction: 0.8846\n",
        "# **************************************************\n",
        "# Dice Score for whole prediction: 0.7663\n",
        "# Dice Score for ensembled prediction: 0.7592\n",
        "# **************************************************\n",
        "# Dice Score for whole prediction: 0.7318\n",
        "# Dice Score for ensembled prediction: 0.7432\n",
        "# **************************************************\n",
        "# Dice Score for whole prediction: 0.8730\n",
        "# Dice Score for ensembled prediction: 0.8764\n",
        "# **************************************************\n",
        "# Dice Score for whole prediction: 0.8862\n",
        "# Dice Score for ensembled prediction: 0.8930\n",
        "# **************************************************\n",
        "# Dice Score for whole prediction: 0.7021\n",
        "# Dice Score for ensembled prediction: 0.7184\n",
        "# **************************************************\n",
        "# Dice Score for whole prediction: 0.7940\n",
        "# Dice Score for ensembled prediction: 0.8396\n",
        "# **************************************************\n",
        "# Dice Score for whole prediction: 0.6629\n",
        "# Dice Score for ensembled prediction: 0.6776\n",
        "# **************************************************\n",
        "# Dice Score for whole prediction: 0.8969\n",
        "# Dice Score for ensembled prediction: 0.9105\n",
        "# **************************************************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dice Score for whole prediction: 0.9051\n",
            "Dice Score for ensembled prediction: 0.8460\n"
          ]
        }
      ],
      "source": [
        "ensembled_nifti = nib.Nifti1Image(ensembled, nib.load('AeroPath/1/1_CT_HR.nii.gz').affine)\n",
        "nib.save(ensembled_nifti, f'pred/ensembled/{idx}.nii.gz')\n",
        "\n",
        "# Compute Dice score\n",
        "dice_whole = calc_dice_score(whole, label)\n",
        "print(f'Dice Score for whole prediction: {dice_whole:.4f}')\n",
        "\n",
        "dice_ensembled = calc_dice_score(ensembled, label)\n",
        "print(f'Dice Score for ensembled prediction: {dice_ensembled:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_7544/2687408277.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  pred = torch.tensor(pred).unsqueeze(0).unsqueeze(0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dice Score for whole prediction: 0.4997\n"
          ]
        }
      ],
      "source": [
        "def calc_dice_score(pred, label):\n",
        "    post_pred = Compose([AsDiscrete(argmax=False, to_onehot=2)])\n",
        "    post_label = Compose([AsDiscrete(to_onehot=2)])\n",
        "\n",
        "    # Ensure the inputs have the correct dimensions\n",
        "    pred = torch.tensor(pred).unsqueeze(0).unsqueeze(0)\n",
        "    label = torch.tensor(label).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    prediction_tensor = post_pred(pred)\n",
        "    label_tensor = post_label(label)\n",
        "\n",
        "    # Compute Dice score\n",
        "    dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
        "    dice_metric(y_pred=prediction_tensor, y=label_tensor)\n",
        "\n",
        "    dice_score = dice_metric.aggregate().item()\n",
        "    dice_metric.reset()\n",
        "\n",
        "    return dice_score\n",
        "\n",
        "label = val_data['label'].cpu().numpy()[0, 0, :, :, :]\n",
        "dice_whole = calc_dice_score(pred, label)\n",
        "print(f'Dice Score for whole prediction: {dice_whole:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grzE-kjOI0vS"
      },
      "source": [
        "## Cleanup data directory\n",
        "\n",
        "Remove directory if a temporary was used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfhZOGgOI0vS"
      },
      "outputs": [],
      "source": [
        "if directory is None:\n",
        "    shutil.rmtree(root_dir)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
